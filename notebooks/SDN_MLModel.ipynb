{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41908a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!which python\n",
    "import os\n",
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9883eb0c",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a00f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb             #model algorithm\n",
    "import shap                       #XAI\n",
    "import sklearn                    #machine learning toolkit ; build and test ML models\n",
    "import pandas as pd               #panel data system ; load and prepare data\n",
    "import numpy as np                #numerical python ; fast numeric calculations\n",
    "import matplotlib.pyplot as plt   # python plotting ; visualisation tool \n",
    "import seaborn as sns             # statistical visualisation tool\n",
    "import warnings\n",
    "\n",
    "# Show only important warnings, hide deprecation/future ones\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# DEBUGGING- ENABLE THIS WARNING\n",
    "#warnings.filterwarnings(\"default\")\n",
    "\n",
    "#Optional \n",
    "#print(\"XGBoost version:\", xgb.__version__)\n",
    "#print(\"SHAP version:\", shap.__version__)\n",
    "#print(\"scikit-learn version:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf29f151",
   "metadata": {},
   "source": [
    "Load and process Light EDA on raw csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03086b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df = pd.read_csv(\"Normal_data.csv\")\n",
    "attack1_df = pd.read_csv(\"OVS.csv\")\n",
    "attack2_df = pd.read_csv(\"metasploitable-2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34863dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, name in zip([normal_df, attack1_df, attack2_df],\n",
    "                    [\"Normal\", \"OVS\", \"Metasploitable2\"]):\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(df.shape)\n",
    "    print(df.info())\n",
    "    print(\"Unique labels:\", df['Label'].unique())\n",
    "    print(df['Label'].value_counts())\n",
    "    print(df.isnull().sum().sum(), \"missing values\")\n",
    "   \n",
    "    if name != \"Normal\":\n",
    "        same_cols = df.columns.equals(normal_df.columns)\n",
    "        print(f\"Columns match Normal dataset: {same_cols}\")\n",
    "    print(\"\\n\" + \"-\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04206671",
   "metadata": {},
   "source": [
    "Filter attack datasets, combine datasets, label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc13eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter DDoS/DoS attack traffic from each attack dataset\n",
    "attack1_df = attack1_df[attack1_df[\"Label\"].isin([\"DoS\", \"DDoS\"])]\n",
    "attack2_df = attack2_df[attack2_df[\"Label\"].isin([\"DoS\", \"DDoS\"])]\n",
    "\n",
    "#Data integrity check-are attack types filtered ?\n",
    "print(\"OVS.csv:\")\n",
    "display(attack1_df.head(10))\n",
    "print(\"metasploitable-2.csv:\")\n",
    "display(attack2_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b6fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape structure-Data integrity check\n",
    "print(attack1_df.shape)\n",
    "print(attack2_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e190dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [normal_df, attack1_df, attack2_df]:\n",
    "    df['Label'] = df['Label'].astype(str).str.strip().str.lower()\n",
    "\n",
    "combined_df = pd.concat([normal_df, attack1_df, attack2_df], ignore_index=True)\n",
    "combined_df['Label'] = combined_df['Label'].map({'normal': 0, 'dos': 1, 'ddos': 1})\n",
    "\n",
    "print(combined_df['Label'].unique())\n",
    "print(combined_df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cbf33e",
   "metadata": {},
   "source": [
    "Full EDA on combined dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb40deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FULL EDA START ===\n",
    "#--BASIC INFO\n",
    "print(\"\\n--- Basic Info ---\")\n",
    "print(combined_df.shape)\n",
    "print(combined_df.dtypes.value_counts())\n",
    "combined_df.info()\n",
    "display(combined_df.head(20))\n",
    "\n",
    "#--MISSING VALUES\n",
    "print(\"\\n--- Missing Values ---\")\n",
    "# Check for missing values per column\n",
    "total_missing = combined_df.isnull().sum().sum()\n",
    "print(f\"Total missing values in combined_df: {total_missing}\")\n",
    "# --- If any missing values exist, show top columns affected ---\n",
    "if total_missing > 0:\n",
    "    print(\"\\nMissing values by column:\")\n",
    "    print(combined_df.isnull().sum().sort_values(ascending=False))\n",
    "\n",
    "#--CLASS DISTRIBUTIONS\n",
    "print(\"\\n--- Class Distribution ---\")\n",
    "class_counts = combined_df['Label'].value_counts().sort_index()  # ensures 0 then 1\n",
    "class_percent = combined_df['Label'].value_counts(normalize=True).sort_index() * 100\n",
    "majority = class_counts.max()\n",
    "minority = class_counts.min()\n",
    "ratio = round(majority / minority, 2)\n",
    "num_neg = class_counts.get(0, 0)\n",
    "num_pos = class_counts.get(1, 0)\n",
    "scale_pos_weight = round(num_neg / num_pos, 2)\n",
    "\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"Count\": class_counts,\n",
    "    \"Percentage (%)\": class_percent.round(2)\n",
    "})\n",
    "print(\" CLASS DISTRIBUTION SUMMARY\\n\")\n",
    "print(summary)\n",
    "print(f\"\\n Imbalance Ratio (Majority : Minority) = {ratio} : 1\")\n",
    "print(f\" Recommended scale_pos_weight for XGBoost = {scale_pos_weight}\")\n",
    "\n",
    "#--SUMMARY STATS\n",
    "print(\"\\n--- Descriptive Statistics ---\")\n",
    "display(combined_df.describe().T)\n",
    "display(combined_df.nunique().sort_values(ascending=False).head(20))\n",
    "\n",
    "#--CORRELATION \n",
    "print(\"\\n--- Correlation Analysis ---\")\n",
    "corr = combined_df.select_dtypes(include=[np.number]).corr()\n",
    "corr_label = corr['Label'].sort_values(ascending=False)\n",
    "print(\"\\nTop correlated features with Label:\")\n",
    "print(corr_label.head(10))\n",
    "print(\"\\nLeast correlated features:\")\n",
    "print(corr_label.tail(10))\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0, square=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- SAMPLING FOR PLOTTING ---\n",
    "print(\"\\n--- Sampling for Visualization ---\")\n",
    "plot_sample = combined_df.groupby('Label', group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=0.1, random_state=42)\n",
    ")\n",
    "\n",
    "num_cols = [c for c in plot_sample.select_dtypes(include=[np.number]).columns if c != 'Label'][:10]\n",
    "\n",
    "for col in num_cols:\n",
    "  plt.figure()\n",
    "  sns.histplot(data=plot_sample, x=col, hue='Label', bins=40, kde=False, stat='density', common_norm=False)\n",
    "  plt.title(f'Distribution: {col}')\n",
    "  plt.tight_layout() \n",
    "  plt.show()\n",
    "  \n",
    "for col in num_cols[:5]:\n",
    "  plt.figure()\n",
    "  sns.boxplot(data=plot_sample, x='Label', y=col)\n",
    "  plt.title(f'Boxplot by Label: {col}')\n",
    "  plt.tight_layout() \n",
    "  plt.show()\n",
    "  \n",
    "# --- DATASET SUMMARY ---  \n",
    "print(\" Dataset Summary\")\n",
    "print(f\" Total Missing values: {combined_df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate rows: {combined_df.duplicated().sum()}\")\n",
    "print(\"Numeric columns:\", len(combined_df.select_dtypes(include=[np.number]).columns))\n",
    "print(\"Non-numeric columns:\", len(combined_df.select_dtypes(exclude=[np.number]).columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb822e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN ONLY FOR FULL EDA OUTPUTS\n",
    "\n",
    "import nbformat\n",
    "from nbformat.v4 import new_notebook, new_code_cell\n",
    "\n",
    "# --- Configure these for your project ---\n",
    "notebook_path = \"SDN_MLModel.ipynb\"          # <-- rename to your current .ipynb\n",
    "new_notebook_path = \"EDA_only_with_profile.ipynb\"   # output notebook name\n",
    "data_csv = \"combined_traffic_.csv\"           # fallback CSV to load if combined_df is undefined\n",
    "marker = \"# === FULL EDA START ===\"\n",
    "\n",
    "# --- Load the current notebook ---\n",
    "with open(notebook_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "eda_cells = []\n",
    "eda_started = False\n",
    "\n",
    "for cell in nb.cells:\n",
    "    if cell.cell_type == \"code\" and marker in cell.source:\n",
    "        eda_started = True\n",
    "    if eda_started:\n",
    "        eda_cells.append(cell)\n",
    "\n",
    "if not eda_cells:\n",
    "    raise RuntimeError(f\"Marker not found: {marker}. Add it just before your EDA block.\")\n",
    "\n",
    "# Safety prelude: ensure combined_df exists (or load from CSV)\n",
    "prelude_code = f\"\"\"# Safety prelude: ensure combined_df exists\n",
    "try:\n",
    "    combined_df\n",
    "except NameError:\n",
    "    import pandas as pd\n",
    "    print(\"combined_df not found in scope. Loading from CSV: '{data_csv}'\")\n",
    "    combined_df = pd.read_csv(\"{data_csv}\")\n",
    "print(\"combined_df rows/cols:\", combined_df.shape)\n",
    "\"\"\"\n",
    "\n",
    "# Profiling cell (appended to the end)\n",
    "profile_code = \"\"\"# Generate ydata-profiling HTML report\n",
    "try:\n",
    "    from ydata_profiling import ProfileReport\n",
    "except Exception as e:\n",
    "    print(\"ydata-profiling not available. Install it with:\\\\n  pip install ydata-profiling\")\n",
    "    raise\n",
    "\n",
    "profile = ProfileReport(combined_df, title=\"InSDN Combined Dataset Report\", explorative=True)\n",
    "profile.to_file(\"EDA_Report.html\")\n",
    "print(\"EDA_Report.html generated.\")\n",
    "\"\"\"\n",
    "\n",
    "# Build new notebook: prelude + EDA cells + profiling\n",
    "cells_out = [new_code_cell(prelude_code)] + eda_cells + [new_code_cell(profile_code)]\n",
    "eda_nb = new_notebook(cells=cells_out)\n",
    "eda_nb.metadata = nb.metadata  # preserve kernel / language info\n",
    "\n",
    "with open(new_notebook_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    nbformat.write(eda_nb, f)\n",
    "\n",
    "print(f\"Created '{new_notebook_path}' with {len(cells_out)} cells (including prelude + profiling).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a51639d",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c5fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b7bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DATA CLEANING ---\n",
    "\n",
    "# 1. Drop duplicates (sanity check)\n",
    "before = combined_df.shape[0]\n",
    "combined_df.drop_duplicates(inplace=True)\n",
    "after = combined_df.shape[0]\n",
    "print(f\"Duplicates removed: {before - after}\")\n",
    "\n",
    "# 2. Drop non-predictive / identifier columns (if present)\n",
    "drop_cols = ['Flow ID', 'Src IP', 'Dst IP', 'Timestamp']\n",
    "existing_cols = [c for c in drop_cols if c in combined_df.columns]\n",
    "\n",
    "if existing_cols:\n",
    "    combined_df.drop(columns=existing_cols, inplace=True)\n",
    "    print(f\"Dropped columns: {existing_cols}\")\n",
    "else:\n",
    "    print(\"No identifier columns found to drop.\")\n",
    "\n",
    "# 3. Confirm binary labels (0 = Normal, 1 = Attack)\n",
    "print(\"\\nLabel value counts after encoding:\")\n",
    "print(combined_df['Label'].value_counts())\n",
    "\n",
    "# 4. Quick check for residual missing data\n",
    "print(f\"\\nMissing values remaining: {combined_df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa554f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== FIX LEAKAGE: Content-level dedup + rebuild pipeline =====\n",
    "\n",
    "# 1) Deduplicate by content (hash of all columns) & reset index\n",
    "before = combined_df.shape[0]\n",
    "combined_df = combined_df.loc[\n",
    "    ~pd.util.hash_pandas_object(combined_df, index=False).duplicated()\n",
    "].reset_index(drop=True)\n",
    "after = combined_df.shape[0]\n",
    "print(f\"Content-level duplicates removed: {before - after}\")\n",
    "print(f\"Shape after content-dedup: {combined_df.shape}\")\n",
    "\n",
    "# 2) Rebuild X/y from the cleaned dataframe\n",
    "y = combined_df['Label']\n",
    "X = combined_df.drop(columns=['Label'])\n",
    "\n",
    "# 3) Re-scale features from scratch\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# 4) Recompute correlation reduction (|corr| >= 0.9)\n",
    "corr = X_scaled_df.corr().abs()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "high_corr_features = [c for c in upper.columns if any(upper[c] >= 0.9)]\n",
    "\n",
    "print(f\"Correlated features to drop (≥0.9): {len(high_corr_features)}\")\n",
    "X_refined_df = X_scaled_df.drop(columns=high_corr_features)\n",
    "print(f\"Final feature matrix after reduction: {X_refined_df.shape}\")\n",
    "\n",
    "# 5) Re-split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_refined_df, y,\n",
    "    test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Testing set:  {X_test.shape}\")\n",
    "\n",
    "# 6) Re-check for any overlap between train and test (should be 0 now)\n",
    "train_hashes = pd.util.hash_pandas_object(X_train, index=False)\n",
    "test_hashes  = pd.util.hash_pandas_object(X_test,  index=False)\n",
    "overlap_count = np.intersect1d(train_hashes.values, test_hashes.values).size\n",
    "print(f\"Row overlap between train and test: {overlap_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbddc6be",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c7888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- FEATURE SCALING ---\n",
    "\n",
    "# 1. Separate features (X) and label (y)\n",
    "X = combined_df.drop(columns=['Label'])\n",
    "y = combined_df['Label']\n",
    "\n",
    "# 2. Scale numeric columns\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert back to DataFrame (retain column names)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(f\"Scaled feature matrix shape: {X_scaled_df.shape}\")\n",
    "print(f\"Scaled feature sample:\\n{X_scaled_df.head(5)}\")\n",
    "\n",
    "# --- CORRELATION REDUCTION ---\n",
    "\n",
    "# 3. Compute correlation matrix\n",
    "corr_matrix = X_scaled_df.corr().abs()\n",
    "\n",
    "# 4. Identify highly correlated pairs (|corr| >= 0.9)\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] >= 0.9)]\n",
    "\n",
    "print(f\"\\nHighly correlated features to drop (|corr| ≥ 0.9):\")\n",
    "print(high_corr_features)\n",
    "\n",
    "# 5. Drop correlated features (optional — safe for model simplification)\n",
    "X_refined_df = X_scaled_df.drop(columns=high_corr_features)\n",
    "print(f\"\\nFinal feature matrix shape after correlation reduction: {X_refined_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe67ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- DATA PARTITIONING ---\n",
    "\n",
    "# Use the refined, scaled dataset\n",
    "X = X_refined_df\n",
    "y = y  # already defined earlier (Label column)\n",
    "\n",
    "# 1. Split into train/test (80/20) with stratification to maintain class ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Display class distribution in each split\n",
    "train_dist = y_train.value_counts(normalize=True) * 100\n",
    "test_dist = y_test.value_counts(normalize=True) * 100\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples, {X_train.shape[1]} features\")\n",
    "print(f\"Testing set:  {X_test.shape[0]} samples, {X_test.shape[1]} features\")\n",
    "\n",
    "print(\"\\nClass distribution (%):\")\n",
    "print(pd.DataFrame({\n",
    "    'Train (%)': train_dist.round(2),\n",
    "    'Test (%)': test_dist.round(2)\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993f6e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONFIRMS NO DATA LEAKAGE\n",
    "\n",
    "train_hashes = pd.util.hash_pandas_object(X_train, index=False)\n",
    "test_hashes  = pd.util.hash_pandas_object(X_test, index=False)\n",
    "\n",
    "overlap_count = np.intersect1d(train_hashes.values, test_hashes.values).size\n",
    "print(f\"Row overlap between train and test: {overlap_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a8bb5e",
   "metadata": {},
   "source": [
    "Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3adfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BASELINE XGBOOST TRAINING & EVALUATION ---\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "\n",
    "# 1. Define model\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 2. Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 4. Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# 5. Display results\n",
    "results = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC-AUC'],\n",
    "    'Score': [accuracy, precision, recall, f1, roc_auc]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\\n\")\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "# 6. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal (0)', 'Attack (1)'])\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(\"Confusion Matrix - Baseline XGBoost\")\n",
    "plt.show()\n",
    "\n",
    "# 7. ROC Curve\n",
    "RocCurveDisplay.from_estimator(xgb_model, X_test, y_test)\n",
    "plt.title(\"ROC Curve - Baseline XGBoost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#LEAKAGE SANITY CHECKS\n",
    "\n",
    "# Invariants\n",
    "assert 'Label' not in X_refined_df.columns, \"Label leaked into features!\"\n",
    "print(\"No 'Label' column in features\")\n",
    "\n",
    "# Train/test overlap (should be 0)\n",
    "train_hash = pd.util.hash_pandas_object(X_train, index=False).values\n",
    "test_hash  = pd.util.hash_pandas_object(X_test,  index=False).values\n",
    "overlap = np.intersect1d(train_hash, test_hash).size\n",
    "print(f\"Row overlap between train and test: {overlap}\")\n",
    "\n",
    "# Binary-like columns suspiciously similar to Label\n",
    "bin_like = [c for c in X_refined_df.columns if set(np.unique(X_refined_df[c])).issubset({0,1})]\n",
    "if bin_like:\n",
    "    eq_rates = {c: (X_refined_df[c].values == y.values).mean() for c in bin_like}\n",
    "    sus = sorted(eq_rates.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    print(\"Binary-like columns most similar to Label:\", sus)\n",
    "else:\n",
    "    print(\"No binary-like feature columns detected.\")\n",
    "\n",
    "# Single-feature “too perfect” scorers (AUC per feature on TRAIN)\n",
    "_auc = {}\n",
    "for c in X_train.columns:\n",
    "    try:\n",
    "        auc = roc_auc_score(y_train, X_train[c])\n",
    "        _auc[c] = auc\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "top_auc = sorted(_auc.items(), key=lambda x: abs(x[1]-0.5), reverse=True)[:10]\n",
    "print(\"Top single-feature AUCs on TRAIN (watch for ~1.0 or ~0.0):\")\n",
    "for k,v in top_auc:\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST FEATURE IMPORTANCE\n",
    "\n",
    "fi = pd.Series(xgb_model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 20 features by importance:\\n\")\n",
    "print(fi.head(20))\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "fi.head(20).sort_values().plot(kind='barh')\n",
    "plt.title(\"Top 20 Feature Importances (XGBoost)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7820d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP EXPLAINABILITY\n",
    "\n",
    "# Sample for speed\n",
    "shap_sample = X_test.sample(n=min(5000, len(X_test)), random_state=42)\n",
    "\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(shap_sample)\n",
    "\n",
    "# Global summary\n",
    "shap.summary_plot(shap_values, shap_sample, show=True)\n",
    "\n",
    "# Dependence on top feature from feature importance\n",
    "top_feat = fi.index[0]\n",
    "shap.dependence_plot(top_feat, shap_values, shap_sample, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f685d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Use the same columns you ended up with after correlation pruning\n",
    "selected_cols = list(X_refined_df.columns)\n",
    "\n",
    "# Build UN-SCALED feature matrix with those columns\n",
    "# (combined_df is your cleaned, deduped dataframe before scaling)\n",
    "X_unscaled = combined_df[selected_cols]\n",
    "y_binary   = combined_df['Label']\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),              # fit per fold (no leakage)\n",
    "    ('clf', xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_validate(\n",
    "    pipe, X_unscaled, y_binary,\n",
    "    cv=cv,\n",
    "    scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc'],\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "cv_results = pd.DataFrame({\n",
    "    'accuracy':  scores['test_accuracy'],\n",
    "    'precision': scores['test_precision'],\n",
    "    'recall':    scores['test_recall'],\n",
    "    'f1':        scores['test_f1'],\n",
    "    'roc_auc':   scores['test_roc_auc'],\n",
    "})\n",
    "\n",
    "print(\"\\n5-Fold CV Results (mean ± std):\\n\")\n",
    "print(cv_results.mean().round(6).astype(str) + \" ± \" + cv_results.std().round(6).astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f3b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SHAP INTERACTION ANALYSIS  ---\n",
    "\n",
    "# 0) Sample for speed (keeps class ratio if X_test is stratified)\n",
    "shap_sample = X_test.sample(n=min(4000, len(X_test)), random_state=42)\n",
    "\n",
    "# 1) Build explainer for XGBoost\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "\n",
    "# 2) Compute standard SHAP values (2-D) for dependence plots\n",
    "#    shape: (n_samples, n_features)\n",
    "shap_values = explainer.shap_values(shap_sample)\n",
    "\n",
    "# 3) Compute interaction values (3-D) for interaction summaries\n",
    "#    shape: (n_samples, n_features, n_features)\n",
    "interaction_values = explainer.shap_interaction_values(shap_sample)\n",
    "\n",
    "# If SHAP returns a list (e.g., multiclass), take the first element\n",
    "if isinstance(interaction_values, list):\n",
    "    interaction_values = interaction_values[0]\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[0]\n",
    "\n",
    "# 4) Global interaction summary plot (uses 3-D interaction tensor)\n",
    "shap.summary_plot(interaction_values, shap_sample, show=True)\n",
    "\n",
    "# 5) Rank top interacting feature pairs by mean |interaction|\n",
    "# interaction_values: (n_samples, n_features, n_features)\n",
    "abs_inter = np.abs(interaction_values).mean(axis=0)   # avg over samples\n",
    "np.fill_diagonal(abs_inter, 0.0)                      # ignore self-interactions\n",
    "\n",
    "feature_names = list(shap_sample.columns)\n",
    "pairs = []\n",
    "for i in range(len(feature_names)):\n",
    "    for j in range(i + 1, len(feature_names)):\n",
    "        pairs.append((feature_names[i], feature_names[j], float(abs_inter[i, j])))\n",
    "\n",
    "top_pairs = (\n",
    "    pd.DataFrame(pairs, columns=[\"Feature A\", \"Feature B\", \"Mean |Interaction|\"])\n",
    "      .sort_values(\"Mean |Interaction|\", ascending=False)\n",
    "      .head(10)\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 feature–feature interactions (by mean |interaction|):\\n\")\n",
    "print(top_pairs.to_string(index=False))\n",
    "\n",
    "# 6) Visualize the strongest interaction with a dependence plot\n",
    "#    IMPORTANT: dependence_plot expects 2-D shap_values; we pass the partner as interaction_index\n",
    "topA, topB = top_pairs.iloc[0][\"Feature A\"], top_pairs.iloc[0][\"Feature B\"]\n",
    "shap.dependence_plot(topA, shap_values, shap_sample, interaction_index=topB, show=True)\n",
    "\n",
    "# 7) Optional: Heatmap of interaction strengths for the top M features\n",
    "M = min(12, len(feature_names))\n",
    "total_inter_strength = abs_inter.sum(axis=0)\n",
    "top_idx = np.argsort(-total_inter_strength)[:M]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(abs_inter[np.ix_(top_idx, top_idx)], aspect='auto', cmap='coolwarm')\n",
    "plt.colorbar(label='Mean |interaction|', fraction=0.046, pad=0.04)\n",
    "plt.xticks(range(M), [feature_names[i] for i in top_idx], rotation=90)\n",
    "plt.yticks(range(M), [feature_names[i] for i in top_idx])\n",
    "plt.title(\"Top Feature–Feature Interaction Strengths\", fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8) Optional sanity checks\n",
    "assert shap_sample.shape[0] == shap_values.shape[0], \"Mismatch: samples vs shap_values rows.\"\n",
    "assert shap_sample.shape[1] == shap_values.shape[1], \"Mismatch: features vs shap_values cols.\"\n",
    "assert (\n",
    "    interaction_values.shape[0] == shap_sample.shape[0]\n",
    "    and interaction_values.shape[1] == shap_sample.shape[1]\n",
    "    and interaction_values.shape[2] == shap_sample.shape[1]\n",
    "), \"Interaction tensor shape is unexpected.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
